// Code generated by go-swagger; DO NOT EDIT.

package kafeido_service

// This file was generated by the swagger tool.
// Editing this file might prove futile when you re-run the swagger generate command

import (
	"context"
	"encoding/json"
	"fmt"
	"io"

	"github.com/go-openapi/runtime"
	"github.com/go-openapi/strfmt"
	"github.com/go-openapi/swag"

	"github.com/footprintai/grandturks-client/v2/api/app/kafeido/proto/go-openapiv2/models"
)

// KafeidoServiceCreateModelInferenceReader is a Reader for the KafeidoServiceCreateModelInference structure.
type KafeidoServiceCreateModelInferenceReader struct {
	formats strfmt.Registry
}

// ReadResponse reads a server response into the received o.
func (o *KafeidoServiceCreateModelInferenceReader) ReadResponse(response runtime.ClientResponse, consumer runtime.Consumer) (interface{}, error) {
	switch response.Code() {
	case 200:
		result := NewKafeidoServiceCreateModelInferenceOK()
		if err := result.readResponse(response, consumer, o.formats); err != nil {
			return nil, err
		}
		return result, nil
	default:
		result := NewKafeidoServiceCreateModelInferenceDefault(response.Code())
		if err := result.readResponse(response, consumer, o.formats); err != nil {
			return nil, err
		}
		if response.Code()/100 == 2 {
			return result, nil
		}
		return nil, result
	}
}

// NewKafeidoServiceCreateModelInferenceOK creates a KafeidoServiceCreateModelInferenceOK with default headers values
func NewKafeidoServiceCreateModelInferenceOK() *KafeidoServiceCreateModelInferenceOK {
	return &KafeidoServiceCreateModelInferenceOK{}
}

/*
KafeidoServiceCreateModelInferenceOK describes a response with status code 200, with default header values.

A successful response.
*/
type KafeidoServiceCreateModelInferenceOK struct {
	Payload *models.KafeidoCreateModelInferenceResponse
}

// IsSuccess returns true when this kafeido service create model inference o k response has a 2xx status code
func (o *KafeidoServiceCreateModelInferenceOK) IsSuccess() bool {
	return true
}

// IsRedirect returns true when this kafeido service create model inference o k response has a 3xx status code
func (o *KafeidoServiceCreateModelInferenceOK) IsRedirect() bool {
	return false
}

// IsClientError returns true when this kafeido service create model inference o k response has a 4xx status code
func (o *KafeidoServiceCreateModelInferenceOK) IsClientError() bool {
	return false
}

// IsServerError returns true when this kafeido service create model inference o k response has a 5xx status code
func (o *KafeidoServiceCreateModelInferenceOK) IsServerError() bool {
	return false
}

// IsCode returns true when this kafeido service create model inference o k response a status code equal to that given
func (o *KafeidoServiceCreateModelInferenceOK) IsCode(code int) bool {
	return code == 200
}

// Code gets the status code for the kafeido service create model inference o k response
func (o *KafeidoServiceCreateModelInferenceOK) Code() int {
	return 200
}

func (o *KafeidoServiceCreateModelInferenceOK) Error() string {
	payload, _ := json.Marshal(o.Payload)
	return fmt.Sprintf("[POST /v1/projects/{projectId}/inference][%d] kafeidoServiceCreateModelInferenceOK %s", 200, payload)
}

func (o *KafeidoServiceCreateModelInferenceOK) String() string {
	payload, _ := json.Marshal(o.Payload)
	return fmt.Sprintf("[POST /v1/projects/{projectId}/inference][%d] kafeidoServiceCreateModelInferenceOK %s", 200, payload)
}

func (o *KafeidoServiceCreateModelInferenceOK) GetPayload() *models.KafeidoCreateModelInferenceResponse {
	return o.Payload
}

func (o *KafeidoServiceCreateModelInferenceOK) readResponse(response runtime.ClientResponse, consumer runtime.Consumer, formats strfmt.Registry) error {

	o.Payload = new(models.KafeidoCreateModelInferenceResponse)

	// response payload
	if err := consumer.Consume(response.Body(), o.Payload); err != nil && err != io.EOF {
		return err
	}

	return nil
}

// NewKafeidoServiceCreateModelInferenceDefault creates a KafeidoServiceCreateModelInferenceDefault with default headers values
func NewKafeidoServiceCreateModelInferenceDefault(code int) *KafeidoServiceCreateModelInferenceDefault {
	return &KafeidoServiceCreateModelInferenceDefault{
		_statusCode: code,
	}
}

/*
KafeidoServiceCreateModelInferenceDefault describes a response with status code -1, with default header values.

An unexpected error response.
*/
type KafeidoServiceCreateModelInferenceDefault struct {
	_statusCode int

	Payload *models.RPCStatus
}

// IsSuccess returns true when this kafeido service create model inference default response has a 2xx status code
func (o *KafeidoServiceCreateModelInferenceDefault) IsSuccess() bool {
	return o._statusCode/100 == 2
}

// IsRedirect returns true when this kafeido service create model inference default response has a 3xx status code
func (o *KafeidoServiceCreateModelInferenceDefault) IsRedirect() bool {
	return o._statusCode/100 == 3
}

// IsClientError returns true when this kafeido service create model inference default response has a 4xx status code
func (o *KafeidoServiceCreateModelInferenceDefault) IsClientError() bool {
	return o._statusCode/100 == 4
}

// IsServerError returns true when this kafeido service create model inference default response has a 5xx status code
func (o *KafeidoServiceCreateModelInferenceDefault) IsServerError() bool {
	return o._statusCode/100 == 5
}

// IsCode returns true when this kafeido service create model inference default response a status code equal to that given
func (o *KafeidoServiceCreateModelInferenceDefault) IsCode(code int) bool {
	return o._statusCode == code
}

// Code gets the status code for the kafeido service create model inference default response
func (o *KafeidoServiceCreateModelInferenceDefault) Code() int {
	return o._statusCode
}

func (o *KafeidoServiceCreateModelInferenceDefault) Error() string {
	payload, _ := json.Marshal(o.Payload)
	return fmt.Sprintf("[POST /v1/projects/{projectId}/inference][%d] KafeidoService_CreateModelInference default %s", o._statusCode, payload)
}

func (o *KafeidoServiceCreateModelInferenceDefault) String() string {
	payload, _ := json.Marshal(o.Payload)
	return fmt.Sprintf("[POST /v1/projects/{projectId}/inference][%d] KafeidoService_CreateModelInference default %s", o._statusCode, payload)
}

func (o *KafeidoServiceCreateModelInferenceDefault) GetPayload() *models.RPCStatus {
	return o.Payload
}

func (o *KafeidoServiceCreateModelInferenceDefault) readResponse(response runtime.ClientResponse, consumer runtime.Consumer, formats strfmt.Registry) error {

	o.Payload = new(models.RPCStatus)

	// response payload
	if err := consumer.Consume(response.Body(), o.Payload); err != nil && err != io.EOF {
		return err
	}

	return nil
}

/*
KafeidoServiceCreateModelInferenceBody kafeido service create model inference body
swagger:model KafeidoServiceCreateModelInferenceBody
*/
type KafeidoServiceCreateModelInferenceBody struct {

	// model name
	ModelName string `json:"modelName,omitempty"`

	// model Uri
	ModelURI string `json:"modelUri,omitempty"`

	// named pipeline Id
	NamedPipelineID string `json:"namedPipelineId,omitempty"`

	// runtime version
	RuntimeVersion string `json:"runtimeVersion,omitempty"`
}

// Validate validates this kafeido service create model inference body
func (o *KafeidoServiceCreateModelInferenceBody) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validates this kafeido service create model inference body based on context it is used
func (o *KafeidoServiceCreateModelInferenceBody) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	return nil
}

// MarshalBinary interface implementation
func (o *KafeidoServiceCreateModelInferenceBody) MarshalBinary() ([]byte, error) {
	if o == nil {
		return nil, nil
	}
	return swag.WriteJSON(o)
}

// UnmarshalBinary interface implementation
func (o *KafeidoServiceCreateModelInferenceBody) UnmarshalBinary(b []byte) error {
	var res KafeidoServiceCreateModelInferenceBody
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*o = res
	return nil
}
